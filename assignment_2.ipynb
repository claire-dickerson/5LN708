{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Document Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-03 08:41:10--  http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.tar.gz\n",
      "Resolving kdd.ics.uci.edu (kdd.ics.uci.edu)... 128.195.1.86\n",
      "Connecting to kdd.ics.uci.edu (kdd.ics.uci.edu)|128.195.1.86|:80... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘reuters21578.tar.gz’ not modified on server. Omitting download.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -N http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘reuters_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir reuters_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf reuters21578.tar.gz -C reuters_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-exchanges-strings.lc.txt\t    README.txt\t   reut2-007.sgm  reut2-015.sgm\r\n",
      "all-orgs-strings.lc.txt\t\t    reut2-000.sgm  reut2-008.sgm  reut2-016.sgm\r\n",
      "all-people-strings.lc.txt\t    reut2-001.sgm  reut2-009.sgm  reut2-017.sgm\r\n",
      "all-places-strings.lc.txt\t    reut2-002.sgm  reut2-010.sgm  reut2-018.sgm\r\n",
      "all-topics-strings.lc.txt\t    reut2-003.sgm  reut2-011.sgm  reut2-019.sgm\r\n",
      "cat-descriptions_120396.txt\t    reut2-004.sgm  reut2-012.sgm  reut2-020.sgm\r\n",
      "feldman-cia-worldfactbook-data.txt  reut2-005.sgm  reut2-013.sgm  reut2-021.sgm\r\n",
      "lewis.dtd\t\t\t    reut2-006.sgm  reut2-014.sgm  test.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls reuters_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of relevant files\n",
    "files = []\n",
    "for file in os.listdir('reuters_data/'):\n",
    "    if file.startswith('reut2'):\n",
    "        files.append(file)\n",
    "\n",
    "# Split files into articles\n",
    "texts = []\n",
    "for file in files:    \n",
    "    with open('reuters_data/'+file, 'r', errors='ignore') as infile:\n",
    "        raw_text = ''\n",
    "        for line in infile:\n",
    "            raw_text += line\n",
    "            if line == '</REUTERS>\\n':\n",
    "                raw_text = raw_text.replace('\\n', ' ')\n",
    "                texts.append(raw_text)\n",
    "                raw_text = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of categories\n",
    "topics = []\n",
    "places = []\n",
    "people = []\n",
    "orgs = []\n",
    "exchanges = []\n",
    "companies = []\n",
    "body = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    topic = re.search('<TOPICS>([\\w\\W]*)<\\/TOPICS>', texts[i])\n",
    "    topics.append(topic.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    place = re.search('<PLACES>([\\w\\W]*)<\\/PLACES>', texts[i])\n",
    "    places.append(place.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    peopl = re.search('<PEOPLE>([\\w\\W]*)<\\/PEOPLE>', texts[i])\n",
    "    people.append(peopl.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    org = re.search('<ORGS>([\\w\\W]*)<\\/ORGS>', texts[i])\n",
    "    orgs.append(org.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    exchange = re.search('<EXCHANGES>([\\w\\W]*)<\\/EXCHANGES>', texts[i])\n",
    "    exchanges.append(exchange.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    company = re.search('<COMPANIES>([\\w\\W]*)<\\/COMPANIES>', texts[i])\n",
    "    companies.append(company.group(1).replace('<D>', '').replace('</D>', ' ').split())\n",
    "    \n",
    "    bod = re.search('<BODY>([\\w\\W]*)<\\/BODY>', texts[i])\n",
    "    title = re.search('<TITLE>([\\w\\W]*)<\\/TITLE>', texts[i])\n",
    "    try:\n",
    "        body.append(title.group(1).lower() + ' ' + bod.group(1))\n",
    "    except:\n",
    "        body.append('')\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels for each article to y\n",
    "y_raw = []\n",
    "for i in range(len(topics)):\n",
    "    categories = [topics, places, people, orgs, exchanges, companies]\n",
    "    y_topics = []\n",
    "    for category in categories:\n",
    "        try:\n",
    "            y_topics.append(category[i][0])\n",
    "        except:\n",
    "            continue\n",
    "    y_raw.append(y_topics)\n",
    "\n",
    "# Assign raw texts to X\n",
    "X_raw = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of times each topic referenced\n",
    "counts = {}\n",
    "for elem in y_raw:\n",
    "    for topic in elem:\n",
    "        if topic not in counts:\n",
    "            counts[topic] = 1\n",
    "        else:\n",
    "            counts[topic] += 1\n",
    "            \n",
    "# Create list of topics referenced fewer than 10 times             \n",
    "topics = []\n",
    "for topic in counts:\n",
    "    if counts[topic] < 10:\n",
    "        topics.append(topic)\n",
    "\n",
    "# Remove infrequently mentioned topics from y\n",
    "for topic in topics:\n",
    "    for elem in y_raw:\n",
    "        if topic in elem:\n",
    "            elem.remove(topic)\n",
    "\n",
    "# Remove 'articles' that have no body and no labels            \n",
    "for i, label in enumerate(y_raw):\n",
    "    if label == [] and X_raw[i] == '':\n",
    "        del y_raw[i]\n",
    "        del X_raw[i]\n",
    "            \n",
    "assert len(X_raw) == len(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing and binarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "prob_clf = MultiOutputClassifier(DecisionTreeClassifier(min_samples_split=20, max_depth=50)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7827949901120633\n",
      "Recall: 0.7527733755942948\n",
      "F-score: 0.7674907093229923\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predictions = prob_clf.predict(X_test)\n",
    "print('Precision:', metrics.precision_score(y_test, predictions, average='micro'))\n",
    "print('Recall:', metrics.recall_score(y_test, predictions, average='micro'))\n",
    "print('F-score:', metrics.f1_score(y_true=y_test, y_pred=predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "non_prob_clf = MultiOutputClassifier(PassiveAggressiveClassifier(loss='squared_hinge')).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8903588256614715\n",
      "Recall: 0.7786053882725832\n",
      "F-score: 0.8307406154886708\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predictions = non_prob_clf.predict(X_test)\n",
    "print('Precision:', metrics.precision_score(y_test, predictions, average='micro'))\n",
    "print('Recall:', metrics.recall_score(y_test, predictions, average='micro'))\n",
    "print('F-score:', metrics.f1_score(y_true=y_test, y_pred=predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "\n",
    "# Training set\n",
    "newsgroups_train = fetch_20newsgroups_vectorized(subset='train')\n",
    "X = newsgroups_train['data']\n",
    "y = newsgroups_train['target']\n",
    "\n",
    "# Test set\n",
    "newsgroups_test = fetch_20newsgroups_vectorized(subset='test')\n",
    "X_test = newsgroups_test['data']\n",
    "y_test = newsgroups_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5022)\t0.017109647770728872\n",
      "  (0, 5886)\t0.017109647770728872\n",
      "  (0, 6214)\t0.017109647770728872\n",
      "  (0, 6216)\t0.017109647770728872\n",
      "  (0, 6281)\t0.017109647770728872\n",
      "  (0, 6286)\t0.017109647770728872\n",
      "  (0, 6324)\t0.017109647770728872\n",
      "  (0, 6331)\t0.017109647770728872\n",
      "  (0, 6403)\t0.017109647770728872\n",
      "  (0, 11391)\t0.017109647770728872\n",
      "  (0, 13930)\t0.017109647770728872\n",
      "  (0, 15094)\t0.017109647770728872\n",
      "  (0, 15251)\t0.017109647770728872\n",
      "  (0, 15530)\t0.017109647770728872\n",
      "  (0, 16731)\t0.017109647770728872\n",
      "  (0, 20228)\t0.017109647770728872\n",
      "  (0, 26214)\t0.017109647770728872\n",
      "  (0, 26806)\t0.017109647770728872\n",
      "  (0, 27436)\t0.017109647770728872\n",
      "  (0, 27618)\t0.017109647770728872\n",
      "  (0, 27645)\t0.017109647770728872\n",
      "  (0, 27901)\t0.017109647770728872\n",
      "  (0, 28012)\t0.05132894331218662\n",
      "  (0, 28146)\t0.41063154649749295\n",
      "  (0, 28421)\t0.034219295541457743\n",
      "  :\t:\n",
      "  (9, 96162)\t0.0842151921066519\n",
      "  (9, 97133)\t0.0842151921066519\n",
      "  (9, 100721)\t0.0842151921066519\n",
      "  (9, 100796)\t0.0842151921066519\n",
      "  (9, 102607)\t0.0842151921066519\n",
      "  (9, 104536)\t0.0842151921066519\n",
      "  (9, 106366)\t0.0842151921066519\n",
      "  (9, 106682)\t0.2526455763199557\n",
      "  (9, 108558)\t0.0842151921066519\n",
      "  (9, 108609)\t0.0842151921066519\n",
      "  (9, 110329)\t0.0842151921066519\n",
      "  (9, 111322)\t0.0842151921066519\n",
      "  (9, 114428)\t0.0842151921066519\n",
      "  (9, 114440)\t0.0842151921066519\n",
      "  (9, 114455)\t0.3368607684266076\n",
      "  (9, 114586)\t0.0842151921066519\n",
      "  (9, 114692)\t0.1684303842133038\n",
      "  (9, 114731)\t0.0842151921066519\n",
      "  (9, 115475)\t0.1684303842133038\n",
      "  (9, 115701)\t0.0842151921066519\n",
      "  (9, 116722)\t0.0842151921066519\n",
      "  (9, 123292)\t0.0842151921066519\n",
      "  (9, 123984)\t0.0842151921066519\n",
      "  (9, 124055)\t0.2526455763199557\n",
      "  (9, 124911)\t0.0842151921066519 [17  7 10 10  7  0 12 15  9  0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:10], y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50570897503983\n"
     ]
    }
   ],
   "source": [
    "prob_clf.estimator.fit(X, y)\n",
    "print('Accuracy:', prob_clf.estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8141263940520446\n"
     ]
    }
   ],
   "source": [
    "non_prob_clf.estimator.fit(X, y)\n",
    "print('Accuracy:', non_prob_clf.estimator.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
